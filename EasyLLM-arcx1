7/1/2024
Arcx1 ezLLM

Easy Large langauge MODEL (ezLLM)

We use an image
We use a tensor
it is sent over transformer
to second transformer
to third transformer
to NUtensor
to a NuImage

This works easily as having a prompt (sample of 3 per rgb why not)
the prompt is cut up into pieces over a tensor (activation map)
those pieces are collected from near zero quotients (pieces that matter and pieces that dont) in the second
and in the third is reassembled as a 3d-tensor with its zero-quotients in considerations
---
it is recycled basically to make this before intepretation
---
second half
---
the nu tensor which is a novel idea im using
takes the third, and uses the 3d-activationmap/tensor as a under-the-hood zeroquotient---reasssembling to a second nutensor
the second nutensor is used as a magnetic linkup (of new symbols) for remodeling of the third nutensor
the third nutensor consists of advanced symbols which is translatd over the nuimage
the nuimage is then presented in comparitive of the first image, and effectively its own activation made fully realized.

this is already built in to the render process but i decided to make a llm out of it incase to explain how algorithms would get chopped up
